# Executive Summary

A foundry-fabricated resistive RAM (RRAM) platform can now solve matrix equations with floating-point precision while retaining the speed and efficiency advantages of analogue computing. The High-Precision Inversion (HP-INV) scheme combines a 3-bit analogue inversion loop with bit-sliced high-precision matrix–vector multiplications, delivering 24-bit fixed-point accuracy on 16×16 systems within ten iterations. The approach keeps the entire refinement process in the analogue domain, reducing data movement and cutting latency to ~120 ns for inversion and ~60 ns for multiplication.

To scale beyond small arrays, the BlockAMC algorithm partitions large matrices into submatrices that fit existing 8×8 RRAM tiles. This strategy enables 16×16 inversions without reprogramming overhead and demonstrates relative errors on the order of 10⁻⁷. When applied to massive MIMO zero-forcing detection with 256-QAM, HP-INV matches 32-bit floating-point digital processors after only two to three iterations, outperforming traditional analogue solutions that lack precision.

Benchmark projections, anchored in measured device performance across different RRAM materials (HfO₂, TaOₓ, TiO₂, NiOₓ, CoOₓ), indicate a tenfold throughput advantage and three- to fivefold energy savings over contemporary GPU and ASIC baselines for N = 128 matrices. With faster operational amplifiers, gains could expand toward three orders of magnitude. The RRAM arrays exhibit eight stable conductance levels programmed via the ASAP write–verify method, achieving 100% yield across 400 devices, while physics-based simulations confirm resilience to material-specific variability, temperature effects, and device aging. Remaining challenges include integrating larger LP-INV arrays, mitigating drift through confirm cycles or redundancy, and co-packaging analogue accelerators with RF front ends or edge AI systems. Overall, HP-INV validates material-specific analogue in-memory computing as a viable path to high-precision, high-throughput linear algebra for communications, scientific computing, and advanced machine learning workloads.
