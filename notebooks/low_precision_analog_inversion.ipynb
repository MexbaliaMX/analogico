{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low-Precision Analogue Inversion Sandbox\n",
    "\n",
    "This notebook emulates the low-precision analogue inversion stage (A₀⁻¹) described in the HP-INV paper.\n",
    "We model a 3-bit resistive array, inject analogue noise, and inspect how residuals evolve during\n",
    "iterative refinement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage\n",
    "- Adjust the matrix size, condition number, quantisation bits, and noise standard deviation in the parameters cell.\n",
    "- Run the simulation cell to observe residual decay and error trajectories.\n",
    "- Optional: Experiment with harsher noise or ill-conditioned matrices to stress-test convergence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation parameters\n",
    "MATRIX_SIZE = 8\n",
    "TARGET_CONDITION = 8.0  # aim for kappa(A) ≈ TARGET_CONDITION\n",
    "ANALOG_BITS = 3\n",
    "NOISE_STD = 1e-2  # gaussian noise added to analogue inversion output\n",
    "MAX_ITERS = 10\n",
    "SEED = 42\n",
    "\n",
    "rng = np.random.default_rng(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_matrix(n: int, condition: float, rng: np.random.Generator) -> np.ndarray:\n",
    "    \"\"\"Create an n×n matrix with approximately the requested condition number.\"\"\"\n",
    "    u, _s, vt = np.linalg.svd(rng.normal(size=(n, n)))\n",
    "    singulars = np.geomspace(condition, 1.0, num=n)\n",
    "    s = np.diag(singulars)\n",
    "    return u @ s @ vt\n",
    "\n",
    "def quantise_symmetrically(a: np.ndarray, bits: int) -> Tuple[np.ndarray, float]:\n",
    "    \"\"\"Quantise matrix entries to symmetric levels using the provided bit-depth.\"\"\"\n",
    "    levels = 2 ** bits\n",
    "    max_abs = np.max(np.abs(a))\n",
    "    if max_abs == 0:\n",
    "        return a.copy(), 1.0\n",
    "    step = max_abs / (levels // 2 - 1)\n",
    "    quantised = np.clip(np.round(a / step), -(levels // 2 - 1), levels // 2 - 1) * step\n",
    "    return quantised, step\n",
    "\n",
    "def analogue_lp_inverse(a_lp: np.ndarray, b: np.ndarray, noise_std: float, rng: np.random.Generator) -> np.ndarray:\n",
    "    \"\"\"Simulate the low-precision analogue inversion with additive gaussian noise.\"\"\"\n",
    "    x = np.linalg.solve(a_lp, b)\n",
    "    noise = rng.normal(scale=noise_std, size=x.shape)\n",
    "    return x + noise\n",
    "\n",
    "def run_simulation(n: int, condition: float, bits: int, noise_std: float, max_iters: int, rng: np.random.Generator) -> Dict[str, List[float]]:\n",
    "    a = generate_matrix(n, condition, rng)\n",
    "    x_true = rng.normal(size=(n,))\n",
    "    b = a @ x_true\n",
    "\n",
    "    a_lp, step = quantise_symmetrically(a, bits)\n",
    "\n",
    "    residuals = []\n",
    "    errors = []\n",
    "    x_est = np.zeros_like(x_true)\n",
    "    r = b - a @ x_est\n",
    "\n",
    "    for _ in range(max_iters):\n",
    "        delta = analogue_lp_inverse(a_lp, r, noise_std, rng)\n",
    "        x_est = x_est + delta\n",
    "        r = b - a @ x_est\n",
    "\n",
    "        residuals.append(np.linalg.norm(r))\n",
    "        errors.append(np.linalg.norm(x_est - x_true) / np.linalg.norm(x_true))\n",
    "\n",
    "    return {\"A\": a, \"A_lp\": a_lp, \"step\": step, \"residuals\": residuals, \"errors\": errors}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_simulation(\n",
    "    n=MATRIX_SIZE,\n",
    "    condition=TARGET_CONDITION,\n",
    "    bits=ANALOG_BITS,\n",
    "    noise_std=NOISE_STD,\n",
    "    max_iters=MAX_ITERS,\n",
    "    rng=rng,\n",
    ")\n",
    "\n",
    "iters = np.arange(1, MAX_ITERS + 1)\n",
    "residuals_log2 = np.log2(results['residuals'])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axes[0].plot(iters, residuals_log2, marker='o')\n",
    "axes[0].set_title('Residual Norm (log₂)')\n",
    "axes[0].set_xlabel('Iteration')\n",
    "axes[0].set_ylabel('log₂‖rₖ‖₂')\n",
    "\n",
    "axes[1].plot(iters, results['errors'], marker='o', color='tab:orange')\n",
    "axes[1].set_title('Relative Error vs. Iteration')\n",
    "axes[1].set_xlabel('Iteration')\n",
    "axes[1].set_ylabel('‖x̂ₖ − x*‖ / ‖x*‖')\n",
    "\n",
    "fig.suptitle('Low-Precision Analogue Inversion Sandbox', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Quantised Matrix\n",
    "The cell below compares the original matrix to its 3-bit analogue representation. Large quantisation steps\n",
    "illustrate the limited precision that the iterative refinement must overcome.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def format_matrix(mat: np.ndarray) -> pd.DataFrame:\n",
    "    return pd.DataFrame(mat).round(4)\n",
    "\n",
    "pd.concat(\n",
    "    {\n",
    "        'A (ideal)': format_matrix(results['A']),\n",
    "        f'A_lp ({ANALOG_BITS}-bit)': format_matrix(results['A_lp']),\n",
    "    },\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments to Try\n",
    "- Increase `TARGET_CONDITION` to 50 or 100 and observe how convergence slows.\n",
    "- Raise `NOISE_STD` to emulate driftier analogue hardware.\n",
    "- Change `ANALOG_BITS` to 2 or 4 to explore quantisation trade-offs.\n",
    "- Inject structured noise (e.g., bias) inside `analogue_lp_inverse` to mimic systematic offsets.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
  "pygments_lexer": "ipython3",
  "nbconvert_exporter": "python",
  "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
