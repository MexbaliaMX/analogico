{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BlockAMC: Scalability Algorithm for Large Matrices\n",
    "\n",
    "This notebook demonstrates the BlockAMC scalability approach for handling large matrices using the Block HP-INV algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add the project root to the path\n",
    "sys.path.insert(0, os.path.join(os.getcwd()))\n",
    "\n",
    "from src.hp_inv import hp_inv, block_hp_inv\n",
    "from src.rram_model import create_rram_matrix\n",
    "from src.redundancy import apply_redundancy\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to BlockAMC Concept\n",
    "\n",
    "BlockAMC (Block Analogue Matrix Computing) partitions large matrices into block submatrices, allowing 8x8 RRAM arrays to solve larger systems without reprogramming. This notebook demonstrates an implementation of this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a larger matrix to demonstrate block partitioning\n",
    "large_n = 16\n",
    "block_size = 8\n",
    "\n",
    "print(f\"Creating a {large_n}x{large_n} matrix to demonstrate BlockAMC\")\n",
    "print(f\"This will be partitioned into blocks of size {block_size}x{block_size}\")\n",
    "\n",
    "# Generate a large RRAM matrix with realistic parameters\n",
    "G_large = create_rram_matrix(large_n, variability=0.03, stuck_fault_prob=0.015, line_resistance=1.7e-3)\n",
    "# Add diagonal dominance to ensure the matrix is well-conditioned\n",
    "G_large = G_large + 0.4 * np.eye(large_n)\n",
    "\n",
    "# Apply redundancy to handle stuck-at faults\n",
    "G_large_repaired = apply_redundancy(G_large)\n",
    "\n",
    "print(f\"Original matrix condition number: {np.linalg.cond(G_large):.2f}\")\n",
    "print(f\"Repaired matrix condition number: {np.linalg.cond(G_large_repaired):.2f}\")\n",
    "\n",
    "# Visualize the large matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(G_large_repaired, cmap='viridis', aspect='equal')\n",
    "plt.colorbar(label='Conductance (S)')\n",
    "plt.title(f'{large_n}x{large_n} RRAM Matrix (After Redundancy Application)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Comparing Standard HP-INV vs Block HP-INV\n",
    "\n",
    "Let's compare the performance of standard HP-INV with Block HP-INV on the large matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate right-hand side vector\n",
    "b_large = np.random.randn(large_n)\n",
    "\n",
    "# For reference, solve using standard numpy (for well-conditioned system)\n",
    "x_true_large = np.linalg.solve(G_large_repaired, b_large)\n",
    "\n",
    "# Solve using standard HP-INV (this may be slower for larger matrices)\n",
    "print(\"Solving with standard HP-INV...\")\n",
    "x_std, iters_std, info_std = hp_inv(G_large_repaired, b_large, bits=3, lp_noise_std=0.01, max_iter=25, tol=1e-5)\n",
    "rel_error_std = np.linalg.norm(x_std - x_true_large) / np.linalg.norm(x_true_large)\n",
    "\n",
    "# Solve using Block HP-INV\n",
    "print(\"Solving with Block HP-INV...\")\n",
    "x_block, iters_block, info_block = block_hp_inv(\n",
    "    G_large_repaired, \n",
    "    b_large, \n",
    "    block_size=block_size, \n",
    "    bits=3, \n",
    "    lp_noise_std=0.01, \n",
    "    max_iter=25, \n",
    "    tol=1e-5\n",
    ")\n",
    "rel_error_block = np.linalg.norm(x_block - x_true_large) / np.linalg.norm(x_true_large)\n",
    "\n",
    "# Compare results\n",
    "print(f\"\\nStandard HP-INV Results:\")\n",
    "print(f\"  Iterations: {iters_std}\")\n",
    "print(f\"  Relative Error: {rel_error_std:.2e}\")\n",
    "print(f\"  Final Residual: {info_std['final_residual']:.2e}\")\n",
    "print(f\"  Converged: {info_std['converged']}\")\n",
    "\n",
    "print(f\"\\nBlock HP-INV Results:\")\n",
    "print(f\"  Iterations: {iters_block}\")\n",
    "print(f\"  Relative Error: {rel_error_block:.2e}\")\n",
    "print(f\"  Converged: {info_block['converged']}\")\n",
    "\n",
    "# Plot comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot convergence residuals\n",
    "ax1.semilogy(info_std['residuals'], 'o-', label='Standard HP-INV', linewidth=2, markersize=6)\n",
    "if 'residuals' in info_block:\n",
    "    ax1.semilogy(info_block['residuals'], 's-', label='Block HP-INV', linewidth=2, markersize=6)\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Residual Norm')\n",
    "ax1.set_title('Convergence Comparison')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot solutions comparison\n",
    "ax2.plot(x_true_large, 'o-', label='True Solution', linewidth=2, markersize=4)\n",
    "ax2.plot(x_std, 's-', label=f'Std HP-INV (err: {rel_error_std:.2e})', linewidth=2, markersize=4)\n",
    "ax2.plot(x_block, '^-', label=f'Block HP-INV (err: {rel_error_block:.2e})', linewidth=2, markersize=4)\n",
    "ax2.set_xlabel('Index')\n",
    "ax2.set_ylabel('Value')\n",
    "ax2.set_title('Solution Comparison')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Performance Analysis of BlockAMC with Different Block Sizes\n",
    "\n",
    "Let's analyze how different block sizes affect the performance of the Block HP-INV algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test with different block sizes\n",
    "matrix_size = 16\n",
    "G_test = create_rram_matrix(matrix_size, variability=0.02, stuck_fault_prob=0.01)\n",
    "G_test = G_test + 0.3 * np.eye(matrix_size)  # Add diagonal dominance\n",
    "G_test = apply_redundancy(G_test)\n",
    "b_test = np.random.randn(matrix_size)\n",
    "\n",
    "# True solution for comparison\n",
    "x_true = np.linalg.solve(G_test, b_test)\n",
    "\n",
    "# Define different block sizes to test\n",
    "block_sizes = [4, 8, 16]  # 16 would mean no blocking\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "for block_size in block_sizes:\n",
    "    if block_size >= matrix_size:\n",
    "        # For block size >= matrix size, use standard HP-INV\n",
    "        x, iters, info = hp_inv(G_test, b_test, bits=3, lp_noise_std=0.01, max_iter=20, tol=1e-5)\n",
    "    else:\n",
    "        x, iters, info = block_hp_inv(\n",
    "            G_test, b_test, block_size=block_size, \n",
    "            bits=3, lp_noise_std=0.01, max_iter=20, tol=1e-5\n",
    "        )\n",
    "    \n",
    "    rel_error = np.linalg.norm(x - x_true) / np.linalg.norm(x_true)\n",
    "    results.append({\n",
    "        'block_size': block_size,\n",
    "        'iterations': iters,\n",
    "        'error': rel_error,\n",
    "        'converged': info.get('converged', False)\n",
    "    })\n",
    "    \n",
    "    print(f\"Block size {block_size}: {iters} iterations, error: {rel_error:.2e}, converged: {info.get('converged', False)}\")\n",
    "\n",
    "# Plot results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot iterations vs block size\n",
    "ax1.plot([r['block_size'] for r in results], [r['iterations'] for r in results], \n",
    "         'o-', linewidth=2, markersize=8)\n",
    "ax1.set_xlabel('Block Size')\n",
    "ax1.set_ylabel('Iterations to Convergence')\n",
    "ax1.set_title('Convergence Speed vs Block Size')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot error vs block size\n",
    "ax2.plot([r['block_size'] for r in results], [r['error'] for r in results], \n",
    "         's-', linewidth=2, markersize=8)\n",
    "ax2.set_xlabel('Block Size')\n",
    "ax2.set_ylabel('Relative Error')\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_title('Solution Accuracy vs Block Size')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scalability Analysis\n",
    "\n",
    "Let's examine how the BlockAMC approach scales with matrix size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test scalability with different matrix sizes\n",
    "matrix_sizes = [8, 12, 16, 20]\n",
    "block_size = 8\n",
    "n_tests = 5  # Number of tests per size to average results\n",
    "\n",
    "# Store scalability results\n",
    "scalability_results = []\n",
    "\n",
    "for size in matrix_sizes:\n",
    "    std_times = []\n",
    "    block_times = []\n",
    "    std_errors = []\n",
    "    block_errors = []\n",
    "    \n",
    "    print(f\"Testing matrix size {size}x{size}...\")\n",
    "    \n",
    "    for i in range(n_tests):\n",
    "        # Create test matrix\n",
    "        G = create_rram_matrix(size, variability=0.02, stuck_fault_prob=0.01)\n",
    "        G = G + 0.3 * np.eye(size)  # Add diagonal dominance\n",
    "        G = apply_redundancy(G)\n",
    "        b = np.random.randn(size)\n",
    "        x_true = np.linalg.solve(G, b)\n",
    "        \n",
    "        # Time standard HP-INV\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        x_std, iters_std, _ = hp_inv(G, b, bits=3, lp_noise_std=0.01, max_iter=15, tol=1e-4)\n",
    "        std_time = time.time() - start_time\n",
    "        std_error = np.linalg.norm(x_std - x_true) / np.linalg.norm(x_true)\n",
    "        \n",
    "        # Time Block HP-INV\n",
    "        start_time = time.time()\n",
    "        x_block, iters_block, _ = block_hp_inv(G, b, block_size=block_size, \n",
    "                                               bits=3, lp_noise_std=0.01, max_iter=15, tol=1e-4)\n",
    "        block_time = time.time() - start_time\n",
    "        block_error = np.linalg.norm(x_block - x_true) / np.linalg.norm(x_true)\n",
    "        \n",
    "        std_times.append(std_time)\n",
    "        block_times.append(block_time)\n",
    "        std_errors.append(std_error)\n",
    "        block_errors.append(block_error)\n",
    "    \n",
    "    # Store averaged results\n",
    "    scalability_results.append({\n",
    "        'size': size,\n",
    "        'avg_std_time': np.mean(std_times),\n",
    "        'avg_block_time': np.mean(block_times),\n",
    "        'avg_std_error': np.mean(std_errors),\n",
    "        'avg_block_error': np.mean(block_errors)\n",
    "    })\n",
    "\n",
    "# Plot scalability results\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Time comparison\n",
    "ax1.plot([r['size'] for r in scalability_results], \n",
    "         [r['avg_std_time'] for r in scalability_results], \n",
    "         'o-', label='Standard HP-INV', linewidth=2, markersize=6)\n",
    "ax1.plot([r['size'] for r in scalability_results], \n",
    "         [r['avg_block_time'] for r in scalability_results], \n",
    "         's-', label='Block HP-INV', linewidth=2, markersize=6)\n",
    "ax1.set_xlabel('Matrix Size')\n",
    "ax1.set_ylabel('Average Time (s)')\n",
    "ax1.set_title('Computation Time vs Matrix Size')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Error comparison\n",
    "ax2.plot([r['size'] for r in scalability_results], \n",
    "         [r['avg_std_error'] for r in scalability_results], \n",
    "         'o-', label='Standard HP-INV', linewidth=2, markersize=6)\n",
    "ax2.plot([r['size'] for r in scalability_results], \n",
    "         [r['avg_block_error'] for r in scalability_results], \n",
    "         's-', label='Block HP-INV', linewidth=2, markersize=6)\n",
    "ax2.set_xlabel('Matrix Size')\n",
    "ax2.set_ylabel('Average Relative Error')\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_title('Solution Accuracy vs Matrix Size')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Time efficiency improvement\n",
    "time_ratios = [r['avg_std_time'] / max(r['avg_block_time'], 1e-8) for r in scalability_results]\n",
    "ax3.bar(range(len(matrix_sizes)), time_ratios, tick_label=matrix_sizes, alpha=0.7)\n",
    "ax3.set_xlabel('Matrix Size')\n",
    "ax3.set_ylabel('Time Ratio (Std / Block)')\n",
    "ax3.set_title('Time Efficiency Improvement with BlockAMC')\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(time_ratios):\n",
    "    ax3.text(i, v + 0.01, f'{v:.2f}x', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Error ratio\n",
    "error_ratios = [max(r['avg_block_error'], 1e-8) / max(r['avg_std_error'], 1e-8) for r in scalability_results]\n",
    "ax4.bar(range(len(matrix_sizes)), error_ratios, tick_label=matrix_sizes, alpha=0.7, color='orange')\n",
    "ax4.set_xlabel('Matrix Size')\n",
    "ax4.set_ylabel('Error Ratio (Block / Std)')\n",
    "ax4.set_title('Accuracy Comparison (Lower is Better)')\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(error_ratios):\n",
    "    ax4.text(i, v + 0.01 if v > 0 else 0.01, f'{v:.2f}x', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary\n",
    "print(\"\\nScalability Summary:\")\n",
    "for r in scalability_results:\n",
    "    time_efficiency = r['avg_std_time'] / max(r['avg_block_time'], 1e-8)\n",
    "    print(f\"{r['size']}x{r['size']}: Block is {time_efficiency:.2f}x faster, \"\n",
    "          f\"error is {max(r['avg_block_error'], 1e-8)/max(r['avg_std_error'], 1e-8):.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Memory Usage Analysis\n",
    "\n",
    "Let's also compare memory usage between standard and block approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create matrices of different sizes and estimate memory usage\n",
    "import sys\n",
    "\n",
    "def estimate_memory_usage(matrix_size, block_size=None):\n",
    "    \"\"\"Estimate memory usage for matrix operations\"\"\"\n",
    "    n = matrix_size\n",
    "    \n",
    "    # For standard approach: need to store the full matrix\n",
    "    full_matrix_mem = n * n * 8  # 8 bytes per float64\n",
    "    \n",
    "    if block_size is None or block_size >= n:\n",
    "        # Standard approach\n",
    "        return full_matrix_mem\n",
    "    else:\n",
    "        # Block approach: only need to store blocks at a time\n",
    "        block_matrix_mem = block_size * block_size * 8\n",
    "        # Also need some overhead for the full matrix\n",
    "        return block_matrix_mem + full_matrix_mem  # Simplified estimate\n",
    "\n",
    "# Calculate memory usage for different approaches\n",
    "matrix_sizes = [8, 16, 24, 32, 40, 48, 56, 64]\n",
    "block_size = 8\n",
    "\n",
    "std_memory = [estimate_memory_usage(size) for size in matrix_sizes]\n",
    "block_memory = [estimate_memory_usage(size, block_size) for size in matrix_sizes]\n",
    "\n",
    "# Calculate ratios\n",
    "memory_ratios = [s/b for s, b in zip(std_memory, block_memory)]\n",
    "\n",
    "# Create memory analysis plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Memory usage comparison\n",
    "ax1.plot(matrix_sizes, std_memory, 'o-', label='Standard Approach', linewidth=2, markersize=6)\n",
    "ax1.plot(matrix_sizes, block_memory, 's-', label=f'Block Approach (block size={block_size})', linewidth=2, markersize=6)\n",
    "ax1.set_xlabel('Matrix Size')\n",
    "ax1.set_ylabel('Memory Usage (bytes)')\n",
    "ax1.set_title('Memory Usage Comparison')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Memory efficiency ratio\n",
    "ax2.plot(matrix_sizes, memory_ratios, '^-', linewidth=2, markersize=6)\n",
    "ax2.set_xlabel('Matrix Size')\n",
    "ax2.set_ylabel('Memory Efficiency Ratio')\n",
    "ax2.set_title('Memory Efficiency (Standard / Block)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nMemory Usage Summary:\")\n",
    "for i, size in enumerate(matrix_sizes):\n",
    "    std_bytes = std_memory[i]\n",
    "    block_bytes = block_memory[i]\n",
    "    ratio = std_bytes / block_bytes\n",
    "    print(f\"{size}x{size}: Standard={std_bytes/1024:.1f}KB, Block={block_bytes/1024:.1f}KB, \"\n",
    "          f\"{ratio:.2f}x more efficient\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the BlockAMC approach to scalability in the Analogico project:\n",
    "1. The block-based approach can handle matrices larger than the physical RRAM array size\n",
    "2. Performance analysis shows different trade-offs with various block sizes\n",
    "3. Scalability testing reveals how the approach performs with increasing matrix sizes\n",
    "4. Memory efficiency is important for large-scale implementations\n",
    "\n",
    "The BlockAMC algorithm enables large-scale analogue matrix computations by partitioning problems into smaller subproblems that fit within the constraints of physical RRAM arrays."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}